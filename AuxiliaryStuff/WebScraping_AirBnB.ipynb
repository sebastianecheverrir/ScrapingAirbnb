{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adapted from https://github.com/x-technology/airbnb-analytics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "y7lYe290m2rK"
   },
   "outputs": [],
   "source": [
    "# all imports\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "# from selenium import webdriver\n",
    "# from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "# import json\n",
    "import time\n",
    "import datetime\n",
    "import pandas as pd\n",
    "\n",
    "# from multiprocessing import Pool\n",
    "\n",
    "# import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_in_date = datetime.date.today() + datetime.timedelta(days=7)\n",
    "check_out_date = check_in_date + datetime.timedelta(days=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the url to be scrapped\n",
    "# airbnb_url = 'https://www.airbnb.com/s/Mayrhofen--Austria/homes?tab_id=home_tab&refinement_paths%5B%5D=%2Fhomes&date_picker_type=calendar&query=Mayrhofen%2C%20Austria&place_id=ChIJbzLYLzjdd0cRDtGuTzM_vt4&checkin='+\\\n",
    "#              str(check_in_date)+\\\n",
    "#              '&checkout='+\\\n",
    "#              str(check_out_date)+\\\n",
    "#              '&adults=4&source=structured_search_input_header&search_type=autocomplete_click'\n",
    "\n",
    "airbnb_url = 'https://www.airbnb.com/s/Medellin/homes?homes&date_picker_type=calendar&checkin='+\\\n",
    "             str(check_in_date)+\\\n",
    "             '&checkout='+\\\n",
    "             str(check_out_date)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# too many separate extractions\n",
    "#this dictionary contains the information to be extraacted\n",
    "RULES_SEARCH_PAGE = {\n",
    "    'url': {'tag': 'a', 'get': 'href'},\n",
    "    'name': {'tag': 'span', 'class': 't6mzqp7'},\n",
    "    'header': {'tag': 'div', 'class': 't1jojoys'},\n",
    "    'rating_n_reviews': {'tag': 'span', 'class': 'r1dxllyb'},\n",
    "    'price': {'tag': 'span', 'class': '_tyxjp1'},\n",
    "                    }\n",
    "\n",
    "#this function gets the listings \n",
    "def get_listings(search_page):\n",
    "    soup = BeautifulSoup(requests.get(search_page).content, 'html.parser')\n",
    "    listings = soup.find_all('div', 'lxq01kf')\n",
    "\n",
    "    return listings\n",
    "\n",
    "#extract the information of one of the elements in the listings\n",
    "def extract_element(listing_html, params):\n",
    "    # 1. Find the right tag\n",
    "    if 'class' in params:\n",
    "        elements_found = listing_html.find_all(params['tag'], params['class'])\n",
    "    else:\n",
    "        elements_found = listing_html.find_all(params['tag'])\n",
    "\n",
    "    # 2. Extract the right element\n",
    "    tag_order = params.get('order', 0)\n",
    "    element = elements_found[tag_order]\n",
    "        \n",
    "    # 3. Get text\n",
    "    if 'get' in params:\n",
    "        output = element.get(params['get'])\n",
    "    else:\n",
    "        output = element.get_text()\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "xSrDAI2gOLEO"
   },
   "outputs": [],
   "source": [
    "# 1. build all urls\n",
    "# listings_per_page: number of properties shown on each page (15, fixed)\n",
    "#number of pages to analyse (10)\n",
    "def build_urls(main_url, listings_per_page=18, pages_per_location=2):\n",
    "    url_list = []\n",
    "    for i in range(pages_per_location):\n",
    "        offset = listings_per_page * i\n",
    "        url_pagination = main_url + f'&items_offset={offset}'\n",
    "        url_list.append(url_pagination)\n",
    "    \n",
    "    return url_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "r2JMis3fOLK6"
   },
   "outputs": [],
   "source": [
    "# safe function to extract all features from one page containg multiple listings\n",
    "def extract_page_features(soup, rules):\n",
    "    features_dict = {}\n",
    "    for feature in rules:\n",
    "        try:\n",
    "            features_dict[feature] = extract_element(soup, rules[feature])\n",
    "        except:\n",
    "            features_dict[feature] = 'empty'\n",
    "    \n",
    "    return features_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "gEItC3xdOLPk"
   },
   "outputs": [],
   "source": [
    "# 2. Iteratively scrape pages\n",
    "def process_search_pages(url_list):\n",
    "    features_list = []\n",
    "    for page in url_list:\n",
    "        listings = get_listings(page)\n",
    "        for listing in listings:\n",
    "            features = extract_page_features(listing, RULES_SEARCH_PAGE)\n",
    "            features_list.append(features)\n",
    "        time.sleep(2)\n",
    "    df_features = pd.DataFrame(features_list)\n",
    "    df_features['url'] = \"https://airbnb.com\" + df_features['url']    \n",
    "    return df_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "KUPBTKOQOLTs"
   },
   "outputs": [],
   "source": [
    "# build a list of URLs\n",
    "url_list = build_urls(airbnb_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "46FZhTDmmko9"
   },
   "outputs": [],
   "source": [
    "#run the scrapping process\n",
    "df_base_features = process_search_pages(url_list)\n",
    "\n",
    "df_base_features.to_csv(\"Scrapped_AirBnB_Dallas.csv\" , mode='a', header=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "WebScraping - Session I.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
